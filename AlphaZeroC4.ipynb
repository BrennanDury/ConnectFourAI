{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a106adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--user\", package])\n",
    "\n",
    "install(\"tensorflow\")\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\", \"typing\"])\n",
    "install(\"setproctitle\")\n",
    "install(\"ray==1.7\")\n",
    "install(\"aioredis==1.3.1\")\n",
    "install(\"modin\")\n",
    "import ray\n",
    "import numpy as np\n",
    "from numpy.random import SeedSequence, default_rng\n",
    "\n",
    "from ConnectFour import ConnectFour, GAMENOTOVER, PLAYERNONE\n",
    "from MCTS import get_move\n",
    "from NeuralNetwork import initialize_network, get_network, train_network\n",
    "from DataManager import DataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4317ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iterations of self play and retraining\n",
    "ITERATIONS = 2000\n",
    "\n",
    "# Number of games to play per iteration\n",
    "EPISODES = 100\n",
    "\n",
    "# My Mac has 8 CPUS\n",
    "CPUS = 8\n",
    "ray.init(num_cpus=CPUS, ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c325825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Records a game state into the data\n",
    "def record(new_data, g, pi, flip_pi, result, q):\n",
    "  board = g.get_board().get_arr()\n",
    "  flip = g.get_flip().get_arr()\n",
    "  labels = np.array([(result + q) / 2])\n",
    "  norm_labels = np.append(labels, pi)\n",
    "  flip_labels = np.append(labels, flip_pi)\n",
    "  new_data = np.append(new_data, np.append(board, norm_labels))\n",
    "  new_data = np.append(new_data, np.append(flip, flip_labels))\n",
    "  return new_data\n",
    "\n",
    "# Plays a game\n",
    "def play_game(g, network, rng):\n",
    "  winner = g.get_winner()\n",
    "  if winner != GAMENOTOVER:\n",
    "    if winner == PLAYERNONE:\n",
    "      return 0, np.array([])\n",
    "    else:\n",
    "      return -1, np.array([])\n",
    "  else:\n",
    "    move, pi, q = get_move(g, network, rng, training=True, simulations=800)\n",
    "    flip_pi = np.flip(pi)\n",
    "    g.move(move)\n",
    "    result, new_data = play_game(g, network, rng)\n",
    "    g.undo()\n",
    "    new_data = record(new_data, g, pi, flip_pi, result, q)\n",
    "    return -result, new_data\n",
    "\n",
    "# Executes an episode of self play\n",
    "@ray.remote\n",
    "def self_play(seed):\n",
    "  rng = default_rng(seed)\n",
    "  print('playing')\n",
    "  g = ConnectFour()\n",
    "  network = get_network()\n",
    "  result, new_data = play_game(g, network, rng)\n",
    "  return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9c8789",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initialize_network()\n",
    "data_manager = DataManager()\n",
    "# data_manager.add_data_from_file('')\n",
    "# X, y1, y2, validation = data_manager.get_data()\n",
    "# train_network(X, y1, y2, validation)\n",
    "ss = SeedSequence(12345)  # generate sources of randomness so parallel processes are not correlated\n",
    "seeds = ss.spawn(ITERATIONS * CPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad46b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs the training process\n",
    "for iteration in range(ITERATIONS):\n",
    "  futures = []\n",
    "  for i in range(EPISODES):\n",
    "    # Limit the number of concurrent processes to the number of CPUS\n",
    "    if i > CPUS:\n",
    "      num_ready = i - CPUS\n",
    "      ray.wait(futures, num_returns=num_ready)\n",
    "    futures.append(self_play.remote(seeds[iteration * CPUS + i]))\n",
    "  new_data = ray.get(futures)\n",
    "  data_manager.add_data(new_data)\n",
    "  data_manager.save(f'Data/data{iteration}.txt')\n",
    "  X, y1, y2, validation = data_manager.get_data()\n",
    "  train_network(X, y1, y2, validation)\n",
    "\n",
    "# Note on output: Boards are shown with 1 representing the player who is playing next,\n",
    "# 2 representing the player who just played. Q is the quality from the point of view of\n",
    "# the player who just played."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82abd830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
